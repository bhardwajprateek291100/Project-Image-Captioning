{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Model_Architecture_and_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0hbQrFIDnCp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1259837e-8e0c-4359-8777-1a0f1e55e7d5"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qGI6jkNNPLdF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "96b0b5a4-5ef7-461a-daf7-fb8cde9d4696"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import json\n",
        "from time import time\n",
        "import pickle\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
        "from keras.layers.merge import add\n",
        "import cv2\n",
        "import collections"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "olIr2WdtPSdX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e834fa28-18bb-42af-d6d4-68526288e56f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pUtqNx9_PLdQ",
        "colab": {}
      },
      "source": [
        "from Building_Vocab import load_data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9-UlzxAEPLda"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RBGMSCDkPLdc",
        "colab": {}
      },
      "source": [
        "li = load_data(\"./drive/My Drive/Files/variable_caption_processing.txt\")\n",
        "max_len = li[0]\n",
        "vocab_size = li[1]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "crBAGu-zPLdi",
        "colab": {}
      },
      "source": [
        "embedding_output = np.loadtxt(\"./drive/My Drive/Files/embedding_output.txt\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0q7q2DBkPLdo",
        "colab": {}
      },
      "source": [
        "train_descriptions = load_data(\"./drive/My Drive/Files/train_descriptions.txt\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WMQrpxqxPLdu",
        "colab": {}
      },
      "source": [
        "# Load the train images features from disk\n",
        "with open(\"./drive/My Drive/Files/encoded_train_image_features.pkl\", \"rb\") as encoded_pickle:\n",
        "    encoding_train = pickle.load(encoded_pickle)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A00oAE2XPLdz",
        "colab": {}
      },
      "source": [
        "word_to_idx = load_data(\"./drive/My Drive/Files/word_to_idx.txt\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z07unN5HPLd9"
      },
      "source": [
        "#### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y28NyPdePLd_",
        "colab": {}
      },
      "source": [
        "# image feature extractor model\n",
        "input_img_features = Input(shape=(2048,))\n",
        "inp_img1 = Dropout(0.3)(input_img_features)\n",
        "inp_img2 = Dense(256,activation='relu')(inp_img1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zE3zsrXLPLeF",
        "colab": {}
      },
      "source": [
        "# partial caption sequence model\n",
        "input_captions = Input(shape=(max_len,))\n",
        "inp_cap1 = Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(input_captions)\n",
        "inp_cap2 = Dropout(0.3)(inp_cap1)\n",
        "inp_cap3 = LSTM(256)(inp_cap2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HTouThtdPLeO",
        "colab": {}
      },
      "source": [
        "# decoder (feed forward) model\n",
        "decoder1 = add([inp_img2,inp_cap3])\n",
        "decoder2 = Dense(256,activation='relu')(decoder1)\n",
        "outputs = Dense(vocab_size,activation='softmax')(decoder2)\n",
        "\n",
        "# Combined Model\n",
        "model = Model(inputs=[input_img_features,input_captions],outputs=outputs)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YtEdSS2xPLeT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "dfb9ef11-0979-401d-b772-92515ae6f609"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 35)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, 2048)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 35, 50)       92400       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2048)         0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 35, 50)       0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          524544      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 256)          314368      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256)          0           dense_1[0][0]                    \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          65792       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1848)         474936      dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,472,040\n",
            "Trainable params: 1,472,040\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ej-HBKF6PLeZ",
        "colab": {}
      },
      "source": [
        "model.layers[2].set_weights([embedding_output])\n",
        "model.layers[2].trainable = False"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G_iBsw0MPLeh",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=\"adam\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1svznNifPLem"
      },
      "source": [
        "### Training of Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fkWK5OQDPLen"
      },
      "source": [
        "#### Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vq9sEUxiPLeo",
        "colab": {}
      },
      "source": [
        "def data_generator(train_descriptions, encoding_train, word_to_idx, max_len, num_photos_per_batch):\n",
        "\n",
        "    X1, X2, y = [], [], []\n",
        "\n",
        "    n=0\n",
        "\n",
        "    while True:\n",
        "        \n",
        "        for key, desc_list in train_descriptions.items():\n",
        "            n +=1\n",
        "\n",
        "            photo = encoding_train[key+\".jpg\"]\n",
        "\n",
        "            for desc in desc_list:\n",
        "                \n",
        "                seq = [ word_to_idx[word] for word in desc.split() if word in word_to_idx]  \n",
        "\n",
        "                for i in range(1,len(seq)):\n",
        "\n",
        "                    in_seq = seq[0:i]\n",
        "                    out_seq = seq[i]\n",
        "\n",
        "                    in_seq = pad_sequences([in_seq], maxlen=max_len, value=0, padding='post')[0]\n",
        "\n",
        "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\n",
        "                    X1.append(photo)\n",
        "                    X2.append(in_seq)\n",
        "                    y.append(out_seq)\n",
        "\n",
        "            if n==num_photos_per_batch:\n",
        "                yield [[np.array(X1), np.array(X2)], np.array(y)]\n",
        "                X1, X2, y = [], [], []\n",
        "                n=0"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2HXmIYJUPLeu",
        "colab": {}
      },
      "source": [
        "epochs = 20\n",
        "number_pics_per_bath = 3\n",
        "steps = len(train_descriptions)//number_pics_per_bath"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "72-weBtzPLe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "outputId": "adf4f7cc-05d2-4bc6-e8ba-db2e4f27be4d"
      },
      "source": [
        "## training\n",
        "for i in range(epochs):\n",
        "    generator = data_generator(train_descriptions, encoding_train, word_to_idx, max_len, number_pics_per_bath)\n",
        "    model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
        "    model.save('/content/drive/My Drive/model/model_' + str(i) + '.h5')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 396s 198ms/step - loss: 4.3060\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 392s 196ms/step - loss: 3.5764\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 397s 198ms/step - loss: 3.3191\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 387s 194ms/step - loss: 3.1606\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 386s 193ms/step - loss: 3.0491\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 392s 196ms/step - loss: 2.9609\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 393s 196ms/step - loss: 2.8965\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 394s 197ms/step - loss: 2.8398\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 393s 197ms/step - loss: 2.7942\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 391s 195ms/step - loss: 2.7552\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 390s 195ms/step - loss: 2.7221\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 392s 196ms/step - loss: 2.6900\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 389s 195ms/step - loss: 2.6619\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 390s 195ms/step - loss: 2.6424\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 386s 193ms/step - loss: 2.6204\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 380s 190ms/step - loss: 2.5976\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 382s 191ms/step - loss: 2.5803\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 376s 188ms/step - loss: 2.5662\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 374s 187ms/step - loss: 2.5490\n",
            "Epoch 1/1\n",
            "2000/2000 [==============================] - 371s 186ms/step - loss: 2.5367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d00OzqAqPLe6",
        "colab": {}
      },
      "source": [
        "epochs = 30\n",
        "number_pics_per_bath = 6\n",
        "steps = len(train_descriptions)//number_pics_per_bath"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uCkMSNLBUsfo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "c984ba34-e0ee-43df-a306-2c18f3c80ce5"
      },
      "source": [
        "## training\n",
        "for i in range(20,epochs):\n",
        "    generator = data_generator(train_descriptions, encoding_train, word_to_idx, max_len, number_pics_per_bath)\n",
        "    model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
        "    model.save('/content/drive/My Drive/model/model_' + str(i) + '.h5')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 210s 210ms/step - loss: 2.4954\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 210s 210ms/step - loss: 2.4691\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 214s 214ms/step - loss: 2.4580\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 214s 214ms/step - loss: 2.4430\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 213s 213ms/step - loss: 2.4283\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 210s 210ms/step - loss: 2.4190\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 210s 210ms/step - loss: 2.4092\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 210s 210ms/step - loss: 2.3990\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 212s 212ms/step - loss: 2.3928\n",
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 210s 210ms/step - loss: 2.3806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ohOqIT0gE6w9",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}