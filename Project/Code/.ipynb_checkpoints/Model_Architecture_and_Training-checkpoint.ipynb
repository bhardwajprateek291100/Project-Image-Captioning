{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "d0hbQrFIDnCp",
    "outputId": "1259837e-8e0c-4359-8777-1a0f1e55e7d5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qGI6jkNNPLdF",
    "outputId": "96b0b5a4-5ef7-461a-daf7-fb8cde9d4696"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import json\n",
    "from time import time\n",
    "import pickle\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
    "from keras.layers.merge import add\n",
    "import cv2\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "olIr2WdtPSdX",
    "outputId": "e834fa28-18bb-42af-d6d4-68526288e56f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pUtqNx9_PLdQ"
   },
   "outputs": [],
   "source": [
    "from Building_Vocab import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-UlzxAEPLda"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBGMSCDkPLdc"
   },
   "outputs": [],
   "source": [
    "li = load_data(\"./drive/My Drive/Files/variable_caption_processing.txt\")\n",
    "max_len = li[0]\n",
    "vocab_size = li[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crBAGu-zPLdi"
   },
   "outputs": [],
   "source": [
    "embedding_output = np.loadtxt(\"./drive/My Drive/Files/embedding_output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0q7q2DBkPLdo"
   },
   "outputs": [],
   "source": [
    "train_descriptions = load_data(\"./drive/My Drive/Files/train_descriptions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WMQrpxqxPLdu"
   },
   "outputs": [],
   "source": [
    "# Load the train images features from disk\n",
    "with open(\"./drive/My Drive/Files/encoded_train_image_features.pkl\", \"rb\") as encoded_pickle:\n",
    "    encoding_train = pickle.load(encoded_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A00oAE2XPLdz"
   },
   "outputs": [],
   "source": [
    "word_to_idx = load_data(\"./drive/My Drive/Files/word_to_idx.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z07unN5HPLd9"
   },
   "source": [
    "#### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y28NyPdePLd_"
   },
   "outputs": [],
   "source": [
    "# image feature extractor model\n",
    "input_img_features = Input(shape=(2048,))\n",
    "inp_img1 = Dropout(0.3)(input_img_features)\n",
    "inp_img2 = Dense(256,activation='relu')(inp_img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zE3zsrXLPLeF"
   },
   "outputs": [],
   "source": [
    "# partial caption sequence model\n",
    "input_captions = Input(shape=(max_len,))\n",
    "inp_cap1 = Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(input_captions)\n",
    "inp_cap2 = Dropout(0.3)(inp_cap1)\n",
    "inp_cap3 = LSTM(256)(inp_cap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTouThtdPLeO"
   },
   "outputs": [],
   "source": [
    "# decoder (feed forward) model\n",
    "decoder1 = add([inp_img2,inp_cap3])\n",
    "decoder2 = Dense(256,activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size,activation='softmax')(decoder2)\n",
    "\n",
    "# Combined Model\n",
    "model = Model(inputs=[input_img_features,input_captions],outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "colab_type": "code",
    "id": "YtEdSS2xPLeT",
    "outputId": "dfb9ef11-0979-401d-b772-92515ae6f609"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 35)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 35, 50)       92400       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 35, 50)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          524544      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          314368      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256)          0           dense_1[0][0]                    \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1848)         474936      dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,472,040\n",
      "Trainable params: 1,472,040\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ej-HBKF6PLeZ"
   },
   "outputs": [],
   "source": [
    "model.layers[2].set_weights([embedding_output])\n",
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_iBsw0MPLeh"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1svznNifPLem"
   },
   "source": [
    "### Training of Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fkWK5OQDPLen"
   },
   "source": [
    "#### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vq9sEUxiPLeo"
   },
   "outputs": [],
   "source": [
    "def data_generator(train_descriptions, encoding_train, word_to_idx, max_len, num_photos_per_batch):\n",
    "\n",
    "    X1, X2, y = [], [], []\n",
    "\n",
    "    n=0\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        for key, desc_list in train_descriptions.items():\n",
    "            n +=1\n",
    "\n",
    "            photo = encoding_train[key+\".jpg\"]\n",
    "\n",
    "            for desc in desc_list:\n",
    "                \n",
    "                seq = [ word_to_idx[word] for word in desc.split() if word in word_to_idx]  \n",
    "\n",
    "                for i in range(1,len(seq)):\n",
    "\n",
    "                    in_seq = seq[0:i]\n",
    "                    out_seq = seq[i]\n",
    "\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_len, value=0, padding='post')[0]\n",
    "\n",
    "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "\n",
    "                    X1.append(photo)\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "\n",
    "            if n==num_photos_per_batch:\n",
    "                yield [[np.array(X1), np.array(X2)], np.array(y)]\n",
    "                X1, X2, y = [], [], []\n",
    "                n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2HXmIYJUPLeu"
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "number_pics_per_bath = 3\n",
    "steps = len(train_descriptions)//number_pics_per_bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "colab_type": "code",
    "id": "72-weBtzPLe0",
    "outputId": "adf4f7cc-05d2-4bc6-e8ba-db2e4f27be4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 396s 198ms/step - loss: 4.3060\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 392s 196ms/step - loss: 3.5764\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 397s 198ms/step - loss: 3.3191\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 387s 194ms/step - loss: 3.1606\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 386s 193ms/step - loss: 3.0491\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 392s 196ms/step - loss: 2.9609\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 393s 196ms/step - loss: 2.8965\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 394s 197ms/step - loss: 2.8398\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 393s 197ms/step - loss: 2.7942\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 391s 195ms/step - loss: 2.7552\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 390s 195ms/step - loss: 2.7221\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 392s 196ms/step - loss: 2.6900\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 389s 195ms/step - loss: 2.6619\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 390s 195ms/step - loss: 2.6424\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 386s 193ms/step - loss: 2.6204\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 380s 190ms/step - loss: 2.5976\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 382s 191ms/step - loss: 2.5803\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 376s 188ms/step - loss: 2.5662\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 374s 187ms/step - loss: 2.5490\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 371s 186ms/step - loss: 2.5367\n"
     ]
    }
   ],
   "source": [
    "## training\n",
    "for i in range(epochs):\n",
    "    generator = data_generator(train_descriptions, encoding_train, word_to_idx, max_len, number_pics_per_bath)\n",
    "    model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "    model.save('/content/drive/My Drive/model/model_' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d00OzqAqPLe6"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "number_pics_per_bath = 6\n",
    "steps = len(train_descriptions)//number_pics_per_bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "uCkMSNLBUsfo",
    "outputId": "c984ba34-e0ee-43df-a306-2c18f3c80ce5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 210s 210ms/step - loss: 2.4954\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 210s 210ms/step - loss: 2.4691\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 214s 214ms/step - loss: 2.4580\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 214s 214ms/step - loss: 2.4430\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 213s 213ms/step - loss: 2.4283\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 210s 210ms/step - loss: 2.4190\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 210s 210ms/step - loss: 2.4092\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 210s 210ms/step - loss: 2.3990\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 212s 212ms/step - loss: 2.3928\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 210s 210ms/step - loss: 2.3806\n"
     ]
    }
   ],
   "source": [
    "## training\n",
    "for i in range(20,epochs):\n",
    "    generator = data_generator(train_descriptions, encoding_train, word_to_idx, max_len, number_pics_per_bath)\n",
    "    model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "    model.save('/content/drive/My Drive/model/model_' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ohOqIT0gE6w9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model_Architecture_and_Training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
